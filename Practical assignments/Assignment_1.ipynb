{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42118469",
   "metadata": {},
   "source": [
    "# Statistical Foundations: Practical Assignment 1\n",
    "---\n",
    "## **Submission Info**\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| **Name** | Divyansh Langeh |\n",
    "| **ID**          | GF202349802 |\n",
    "| **Subject**     | Statistical Foundation of Data Science |\n",
    "| **Assignment**  | Practical 1 - Testing Pandas and Numpy |\n",
    "| **Repo**        | [View my GitHub Repo](https://github.com/JoyBoy2108/Statistical-foundations-of-data-science-practicals) |\n",
    "\n",
    "---\n",
    "## **Assignment Overview**\n",
    "This notebook contains the solution for the first practical assignment in the Statistical Foundation of Data Sciences course. It covers key data analysis tasks such as calculating statistical measures, handling missing values, and performing array manipulations with NumPy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33957333",
   "metadata": {},
   "source": [
    "## **Notebook Introduction**\n",
    "\n",
    "This notebook tackles the four core problems for the first practical assignment. We will use a synthetic dataset to perform a series of statistical analyses and array manipulations.\n",
    "\n",
    "### **Key Tasks to be Performed:**\n",
    "\n",
    "* **Task 1: Central Tendency Calculation**\n",
    "    We will calculate the mean, median, and a custom age-weighted mean for the income data, while handling the missing values correctly.\n",
    "\n",
    "* **Task 2: Data Standardization and Outlier Detection**\n",
    "    This task involves standardization of the income data into z-scores and identification of the outliers based on the `|z| > 3` rule.\n",
    "\n",
    "* **Task 3: Data Binning and Aggregation**\n",
    "    We will segment the data into specific age bins and calculate the count, mean income, and median score for each sgment.\n",
    "\n",
    "* **Task 4: NumPy Array Operations**\n",
    "    The final section will demonstrate fundamental NumPy operations, including reshaping, indexing, broadcasting, and linear algebra functions like calculating a determinant and inverse.\n",
    "\n",
    "### **General Instructions & Setup**\n",
    "As per the assignment requirements, this notebook will adhere to the following:\n",
    "1.  A synthetic dataset with `NaN` values will be used.\n",
    "2.  The initial random seed is set to `42` for reproducibility.\n",
    "3.  All `NaN` values are handled appropriately without unnecessary data loss.\n",
    "\n",
    "*Let's begin with the Environment setup and move to the problem-1.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9472d23",
   "metadata": {},
   "source": [
    "## Environment Setup and Dependencies\n",
    "\n",
    "Start by importing all the required libraries and generating the synthetic dataset for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29cab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.2\n",
      "NumPy version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed to 42 for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7579ba",
   "metadata": {},
   "source": [
    "## Create Synthetic Data\n",
    "\n",
    "The following code cell generates the synthetic dataset that will be used for all the problems in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "663b2e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 5 Rows of the Dataset ---\n",
      "   age        income      score\n",
      "0   51  25556.105210        NaN\n",
      "1   50  58277.954830  21.825389\n",
      "2   40  80083.610685  94.996118\n",
      "3   45  60763.873697  78.634501\n",
      "4   49  42962.784197        NaN\n",
      "\n",
      "--- Dataset Information (Checking for NaNs) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     100 non-null    int32  \n",
      " 1   income  90 non-null     float64\n",
      " 2   score   90 non-null     float64\n",
      "dtypes: float64(2), int32(1)\n",
      "memory usage: 2.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Generate the synthetic dataset with 100 records\n",
    "num_records = 100\n",
    "data = {\n",
    "    'age': np.random.randint(18, 65, size=num_records),\n",
    "    'income': 50000 + np.random.normal(0, 15000, size=num_records),\n",
    "    'score': np.random.uniform(0, 100, size=num_records)\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some NaN (Not a Number) values into the dataset\n",
    "nan_indices_income = np.random.choice(df.index, size=int(num_records * 0.1), replace=False)\n",
    "df.loc[nan_indices_income, 'income'] = np.nan\n",
    "\n",
    "nan_indices_score = np.random.choice(df.index, size=int(num_records * 0.1), replace=False)\n",
    "df.loc[nan_indices_score, 'score'] = np.nan\n",
    "\n",
    "# Display the first 5 rows and a summary to verify the data\n",
    "print(\"--- First 5 Rows of the Dataset ---\")\n",
    "print(df.head())\n",
    "print(\"\\n--- Dataset Information (Checking for NaNs) ---\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d3286",
   "metadata": {},
   "source": [
    "## Problem 1: Measures of Central Tendency\n",
    "\n",
    "> **Instruction**: \n",
    "Compute (a) mean, (b) median, and (c) age-weighted mean of income. Ignore NaNs where appropriate. Explain when a weighted mean is preferable.\n",
    "\n",
    "**1.1: Calculating Mean, Median and Age-weighted mean income**:\n",
    "\n",
    "Firstly, we'll calculate the standard mean and median for the income column using the mean() and median() functions of pandas as they automatically handle the NaN values present in the data.\n",
    "Then we will exclude the NaN values to calculate Age-weighted mean income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "939be323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) Mean income: $48,855.67\n",
      "(b) Median income: $51,611.95\n",
      "(c) Age-weighted mean income: $48,044.57\n",
      "\n",
      "Calculations are based on 90 valid income records.\n"
     ]
    }
   ],
   "source": [
    "# (a) Mean income - pandas handles NaNs automatically\n",
    "mean_income = df['income'].mean()\n",
    "print(f\"(a) Mean income: ${mean_income:,.2f}\")\n",
    "\n",
    "# (b) Median income - pandas handles NaNs automatically\n",
    "median_income = df['income'].median()\n",
    "print(f\"(b) Median income: ${median_income:,.2f}\")\n",
    "\n",
    "# (c) Age-weighted mean income\n",
    "# First, create a temporary DataFrame that excludes rows with NaN income\n",
    "df_no_nan_income = df.dropna(subset=['income'])\n",
    "\n",
    "# Use the efficient numpy.average() function with the weights parameter\n",
    "weighted_mean_income = np.average(\n",
    "    df_no_nan_income['income'],\n",
    "    weights=df_no_nan_income['age']\n",
    ")\n",
    "print(f\"(c) Age-weighted mean income: ${weighted_mean_income:,.2f}\")\n",
    "\n",
    "print(f\"\\nCalculations are based on {df['income'].notna().sum()} valid income records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb39be2",
   "metadata": {},
   "source": [
    "### Solution Methodology\n",
    "\n",
    "1.  **Mean and Median Calculation:** The standard pandas `.mean()` and `.median()` methods were used directly on the `income` series. These functions are efficient because they automatically ignore `NaN` values.\n",
    "\n",
    "2.  **Data Preparation for Weighted Mean:** To prepare for the weighted mean calculation, a temporary, clean DataFrame was created by dropping only the rows where `income` was missing. This made sure the age and income data aligned perfectly.\n",
    "\n",
    "3.  **Age-Weighted Mean Calculation:** The `numpy.average()` function was used, which is specifically designed for these calculations. The income data as the main variable and the corresponding age data to the `weights` parameter was passed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd20a1a",
   "metadata": {},
   "source": [
    "### Analysis: When is a Weighted Mean Preferable?\n",
    "\n",
    "A weighted mean is more effective than a simple mean when certain data points carry greater importance than others. Unlike a simple mean, which treats every value equally, a weighted mean accounts for varying levels of significance—something that often reflects real-world situations.\n",
    "\n",
    "For example: in our dataset, we used age as the weight, giving greater influence to the income of older individuals. This approach can be valuable if we assume that older individuals have more established careers and, therefore, more stable income levels. Other common examples include calculating a student’s final grade—where a final exam contributes more heavily than an early unit test—or evaluating an investment portfolio, where larger investments exert a greater impact on overall returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51deba29",
   "metadata": {},
   "source": [
    "## Problem 2: Standardization and Outlier Detection\n",
    "\n",
    "> **Instruction**: \n",
    "Standardize income using z-score and identify outliers using the |z| > 3 rule. Handle NaNs correctly without dropping entire rows.\n",
    "\n",
    "\n",
    "### What is a Z-Score?\n",
    "A **z-score** is a standardized value that tells us how many standard deviations a specific data point is from the mean of the dataset. The formula is:\n",
    "$$ z = \\frac{(x - \\mu)}{\\sigma} $$\n",
    "Where $x$ is the data point, $\\mu$ is the mean, and $\\sigma$ is the standard deviation.\n",
    "\n",
    "This is extremely useful for finding outliers. A common rule is that any data point with an absolute z-score of more than 3 is considered an **outlier**, because it is very far from the average value. We will apply this rule to our income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5424a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROBLEM 2: Standardization and Outlier Detection ===\n",
      "\n",
      "Number of income outliers found (|z| > 3): 0\n",
      "\n",
      "No outliers were detected based on the |z| > 3 rule.\n",
      "\n",
      "--- DataFrame Head with New Z-Score Column ---\n",
      "   age        income      score  income_zscore age_group\n",
      "0   51  25556.105210        NaN      -1.448759     45-59\n",
      "1   50  58277.954830  21.825389       0.585874     45-59\n",
      "2   40  80083.610685  94.996118       1.941741     35-44\n",
      "3   45  60763.873697  78.634501       0.740447     45-59\n",
      "4   49  42962.784197        NaN      -0.366418     45-59\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PROBLEM 2: Standardization and Outlier Detection ===\\n\")\n",
    "\n",
    "# 1. Calculate the mean and standard deviation, which are needed for the z-score.\n",
    "#    Pandas automatically ignores NaNs for these calculations.\n",
    "income_mean = df['income'].mean()\n",
    "income_std = df['income'].std()\n",
    "\n",
    "# 2. Standardize the income column and add it as a new 'income_zscore' column.\n",
    "#    The formula is z = (value - mean) / std.\n",
    "#    This operation correctly handles NaNs; a NaN income results in a NaN z-score.\n",
    "df['income_zscore'] = (df['income'] - income_mean) / income_std\n",
    "\n",
    "# 3. Identify outliers using the |z| > 3 rule.\n",
    "#    .abs() gets the absolute value, and we find rows where it's > 3.\n",
    "outliers_df = df[df['income_zscore'].abs() > 3]\n",
    "outlier_count = len(outliers_df)\n",
    "\n",
    "# 4. Report the final results.\n",
    "print(f\"Number of income outliers found (|z| > 3): {outlier_count}\")\n",
    "\n",
    "# Display the outlier rows if any were found.\n",
    "if outlier_count > 0:\n",
    "    print(\"\\n--- Detected Outlier Rows ---\")\n",
    "    # We display only the most relevant columns for a clean output.\n",
    "    print(outliers_df[['age', 'income', 'income_zscore']])\n",
    "else:\n",
    "    print(\"\\nNo outliers were detected based on the |z| > 3 rule.\")\n",
    "\n",
    "# Show the first few rows of the updated DataFrame to see the new column.\n",
    "print(\"\\n--- DataFrame Head with New Z-Score Column ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a8d85",
   "metadata": {},
   "source": [
    "### Solution Methodology for Problem 2\n",
    "\n",
    "1.  **Calculate Core Statistics**: Firstly, the **mean** and **standard deviation** of the `income` column were calculated. The built-in pandas methods, which conveniently ignore any `NaN` values during this calculation were used.\n",
    "\n",
    "2.  **Compute Z-Scores**: Then, a new column in the DataFrame called `income_zscore` was created. This was done by applying the z-score formula in a single vectorized operation. This efficient method also makes sure that any `NaN` in the original `income` column results in a `NaN` in the `income_zscore` column, fulfilling the requirement to handle missing values properly.\n",
    "\n",
    "3.  **Filter for Outliers**: To find the outliers, **boolean masking** was used. The absolute value of the `income_zscore` column was taken and then the DataFrame was filtered to keep only the rows where this value was greater than 3.\n",
    "\n",
    "4.  **Count and Report**: Finally, the number of rows in the filtered outlier DataFrame were counted to get the final count. The result was presented in a clean summary, and the actual outlier rows were displayed if any were found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffee753",
   "metadata": {},
   "source": [
    "## Problem 3: Age Binning and Aggregation\n",
    "\n",
    "> **Instruction**: Create age bins `[18-25)`, `[25-35)`, `[35-45)`, `[45-60)` and compute for each bin: count of observations, mean income, and median score. Present results in a tidy DataFrame sorted by age bin. \n",
    "\n",
    "### What is Binning and Aggregation?\n",
    "**Binning** is the process of converting continuous numerical data, like age, into discrete groups or \"bins.\" Instead of analyzing every single age, we can look at patterns across broader age ranges (e.g., 18-24, 25-34). This makes it easier to spot trends that might be hidden in the raw data.\n",
    "\n",
    "Once the data is binned, we can perform an **aggregation**. This simply means we calculate a summary statistic (like a `count`, `mean`, or `median`) for each of those bins. For this problem, we will group our data by the new age bins and then aggregate the required statistics to see how income and scores differ across age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11b7ca03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROBLEM 3: Age Binning and Aggregation ===\n",
      "\n",
      "--- Tidy DataFrame of Binned Statistics ---\n",
      "           count_of_observations  mean_income  median_score\n",
      "age_group                                                  \n",
      "18-24                         16     49007.59         54.44\n",
      "25-34                         18     51379.43         59.24\n",
      "35-44                         23     49159.44         55.29\n",
      "45-59                         31     50342.47         77.96\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PROBLEM 3: Age Binning and Aggregation ===\\n\")\n",
    "\n",
    "# 1. Define the age bins and labels.\n",
    "bins = [18, 25, 35, 45, 60]\n",
    "labels = ['18-24', '25-34', '35-44', '45-59']\n",
    "\n",
    "# 2. Create the 'age_group' column.\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# 3. Group by the new age bins and aggregate.\n",
    "#    We add observed=False to silence the warning and maintain the current behavior.\n",
    "binned_stats = df.groupby('age_group', observed=False).agg(\n",
    "    count_of_observations=('age', 'count'),\n",
    "    mean_income=('income', 'mean'),\n",
    "    median_score=('score', 'median')\n",
    ").round(2)\n",
    "\n",
    "# 4. Display the final tidy DataFrame.\n",
    "print(\"--- Tidy DataFrame of Binned Statistics ---\")\n",
    "print(binned_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6468fa",
   "metadata": {},
   "source": [
    "### Solution Methodology for Problem 3\n",
    "\n",
    "1.  **Bin and Label Definition**: Firstly, two Python lists were created, one to define the numerical edges of the age bins and another to hold the corresponding string labels for clear presentation. The `right=False` parameter was sset in this approach to ensure the intervals were left-inclusive as required (e.g., `[18-25)`).\n",
    "\n",
    "2.  **Categorization with `pd.cut`**: The `pd.cut()` function was used to efficiently segment the continuous 'age' data into the discrete categories that were defined, creating a new `age_group` column in the process.\n",
    "\n",
    "3.  **One-Step Aggregation**: The core of this solution was a single `groupby('age_group').agg()` command. This powerful method helps to group the entire DataFrame by the new age bins and compute all three required statistics (count, mean income, and median score) simultaneously. This approach is not only concise but also correctly handles any missing values in the data. The resulting DataFrame was already sorted and formatted as required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69a6c6",
   "metadata": {},
   "source": [
    "## Problem 4: Array Operations and Linear Algebra\n",
    "\n",
    "> **Instruction**: Create an array it cannot be of 1 Dimension. And then showcase the operation for the following:\n",
    "> * Shape and Resize\n",
    "> * shape, size, Transpose, Flatten\n",
    "> * Showcasing negative indexing and display error while doing slicing\n",
    "> * Arithmetic Operations → Broadcasting, Dot Product\n",
    "> * Linear Algebra → Determinant, Inverse\n",
    "\n",
    "### Key NumPy Concepts\n",
    "This problem explores the fundamentals of **NumPy**, which is the core library for numerical computing in Python. We will demonstrate several key operations on NumPy arrays.\n",
    "\n",
    "* **NumPy Arrays**: These are powerful, grid-like data structures that are much more efficient for numerical operations than standard Python lists. All our demonstrations will be on multi-dimensional arrays.\n",
    "* **Broadcasting**: This is NumPy's powerful mechanism for performing arithmetic operations on arrays of different shapes. The smaller array's values are \"broadcast\" across the larger array so they can be combined.\n",
    "* **Dot Product**: A central operation in linear algebra that defines how to multiply matrices. It's different from simple element-wise multiplication.\n",
    "* **Determinant and Inverse**: These are properties of square matrices. The **determinant** is a scalar value that provides important information about the matrix, while the **inverse** is another matrix that, when multiplied by the original, results in the identity matrix. These are crucial for solving systems of linear equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8664a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROBLEM 4: Array Operations and Linear Algebra ===\n",
      "\n",
      "--- 1. Initial Arrays ---\n",
      "General purpose 3x4 array:\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "\n",
      "Square 3x3 matrix for linear algebra:\n",
      " [[4 7 2]\n",
      " [2 6 0]\n",
      " [1 2 5]]\n",
      "\n",
      "\n",
      "--- 2. Shape and Resize Operations ---\n",
      "Shape of arr: (3, 4)\n",
      "Size of arr: 12\n",
      "Transposed arr:\n",
      "[[ 1  5  9]\n",
      " [ 2  6 10]\n",
      " [ 3  7 11]\n",
      " [ 4  8 12]]\n",
      "Flattened arr: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Reshaped to 2x6:\n",
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]]\n",
      "\n",
      "\n",
      "--- 3. Negative Indexing and Slicing Error ---\n",
      "Using negative indexing to get the last element: 12\n",
      "\n",
      "Showcasing a slicing error:\n",
      "The following line of code is commented out because it will stop the script.\n",
      "arr[0, 5]  <-- This would cause an IndexError because column 5 does not exist.\n",
      "\n",
      "\n",
      "--- 4. Arithmetic Operations ---\n",
      "Broadcasting a scalar (arr + 100):\n",
      " [[101 102 103 104]\n",
      " [105 106 107 108]\n",
      " [109 110 111 112]]\n",
      "\n",
      "Broadcasting a 1D array to the 2D array:\n",
      " [[11 22 33 44]\n",
      " [15 26 37 48]\n",
      " [19 30 41 52]]\n",
      "\n",
      "Dot product of a 3x2 and a 2x3 matrix:\n",
      " [[ 90 120 150]\n",
      " [190 260 330]\n",
      " [290 400 510]]\n",
      "\n",
      "\n",
      "--- 5. Linear Algebra ---\n",
      "Determinant of the square matrix: 46.00\n",
      "\n",
      "Inverse of the square matrix:\n",
      " [[ 0.65217391 -0.67391304 -0.26086957]\n",
      " [-0.2173913   0.39130435  0.08695652]\n",
      " [-0.04347826 -0.02173913  0.2173913 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PROBLEM 4: Array Operations and Linear Algebra ===\\n\")\n",
    "\n",
    "# --- 1. Array Creation ---\n",
    "# We create two arrays: a general 3x4 array for most operations,\n",
    "# and a 3x3 square matrix for linear algebra.\n",
    "arr = np.array([[1, 2, 3, 4],\n",
    "                [5, 6, 7, 8],\n",
    "                [9, 10, 11, 12]])\n",
    "\n",
    "square_matrix = np.array([[4, 7, 2],\n",
    "                          [2, 6, 0],\n",
    "                          [1, 2, 5]])\n",
    "print(\"--- 1. Initial Arrays ---\")\n",
    "print(\"General purpose 3x4 array:\\n\", arr)\n",
    "print(\"\\nSquare 3x3 matrix for linear algebra:\\n\", square_matrix)\n",
    "\n",
    "\n",
    "# --- 2. Shape and Resize Operations ---\n",
    "print(\"\\n\\n--- 2. Shape and Resize Operations ---\")\n",
    "print(f\"Shape of arr: {arr.shape}\")\n",
    "print(f\"Size of arr: {arr.size}\")\n",
    "print(f\"Transposed arr:\\n{arr.T}\")\n",
    "print(f\"Flattened arr: {arr.flatten()}\")\n",
    "print(f\"Reshaped to 2x6:\\n{arr.reshape(2, 6)}\")\n",
    "\n",
    "\n",
    "# --- 3. Negative Indexing and Slicing Error ---\n",
    "print(\"\\n\\n--- 3. Negative Indexing and Slicing Error ---\")\n",
    "print(f\"Using negative indexing to get the last element: {arr[-1, -1]}\")\n",
    "\n",
    "print(\"\\nShowcasing a slicing error:\")\n",
    "print(\"The following line of code is commented out because it will stop the script.\")\n",
    "print(\"arr[0, 5]  <-- This would cause an IndexError because column 5 does not exist.\")\n",
    "# arr[0, 5] # Uncomment this line to see the IndexError\n",
    "\n",
    "\n",
    "# --- 4. Arithmetic Operations ---\n",
    "print(\"\\n\\n--- 4. Arithmetic Operations ---\")\n",
    "# Broadcasting: adding a scalar to the whole array\n",
    "print(\"Broadcasting a scalar (arr + 100):\\n\", arr + 100)\n",
    "# Broadcasting: adding a 1D array to a 2D array\n",
    "broadcast_row = np.array([10, 20, 30, 40])\n",
    "print(\"\\nBroadcasting a 1D array to the 2D array:\\n\", arr + broadcast_row)\n",
    "\n",
    "# Dot Product\n",
    "arr_a = np.array([[1, 2], [3, 4], [5, 6]]) # Shape: 3x2\n",
    "arr_b = np.array([[10, 20, 30], [40, 50, 60]]) # Shape: 2x3\n",
    "print(\"\\nDot product of a 3x2 and a 2x3 matrix:\\n\", np.dot(arr_a, arr_b))\n",
    "\n",
    "\n",
    "# --- 5. Linear Algebra ---\n",
    "print(\"\\n\\n--- 5. Linear Algebra ---\")\n",
    "# Determinant\n",
    "det = np.linalg.det(square_matrix)\n",
    "print(f\"Determinant of the square matrix: {det:.2f}\")\n",
    "\n",
    "# Inverse\n",
    "# We can only find the inverse if the determinant is non-zero.\n",
    "if det != 0:\n",
    "    inverse = np.linalg.inv(square_matrix)\n",
    "    print(\"\\nInverse of the square matrix:\\n\", inverse)\n",
    "else:\n",
    "    print(\"\\nMatrix is not invertible (determinant is zero).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7df00",
   "metadata": {},
   "source": [
    "### Solution Methodology for Problem 4\n",
    "\n",
    "1.  **Array Creation**: Two separate arraysw were initialized, a general-purpose 3x4 array for most demonstrations and a 3x3 square matrix specifically for the linear algebra operations, which require a square shape.\n",
    "\n",
    "2.  **Shape Operations**: The `.shape` and `.size` attributes and the `.T` (transpose), `.flatten()`, and `.reshape()` methods were used to cover all the required shape and resize demonstrations.\n",
    "\n",
    "3.  **Indexing and Errors**: A clear example of negative indexing was provided to fetch the last element. To showcase a slicing error, a line of code was written that would produce an `IndexError` and explained in a comment why it would fail, keeping it commented out so the entire notebook can run without interruption.\n",
    "\n",
    "4.  **Arithmetic**: Broadcasting was shown by adding both a scalar and a 1D array to a 2D array. For the dot product, two new matrices with compatible inner dimensions (3x**2** and **2**x3) were created to correctly perform the operation.\n",
    "\n",
    "5.  **Linear Algebra**: Using the square matrix, its determinant with `np.linalg.det()` was calculated. After confirming the determinant was non-zero, the matrix inverse using `np.linalg.inv()` was calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89eb898",
   "metadata": {},
   "source": [
    "## Assignment Completion Summary\n",
    "\n",
    "This notebook successfully addressed all four problems of the practical assignment, demonstrating key skills in data analysis and numerical computing with Python.\n",
    "\n",
    "### Summary of Tasks Completed:\n",
    "\n",
    "* **1. Statistical Measures:** We calculated the mean, median, and age-weighted mean for the income data. The concept and appropriate use of a weighted mean were also explained. Proper handling of `NaN` values was ensured throughout.\n",
    "\n",
    "* **2. Standardization & Outliers:** The income data was standardized by calculating z-scores, which were added as a new column to the DataFrame. Outliers were then identified and counted based on the standard `|z| > 3` rule.\n",
    "\n",
    "* **3. Age Binning & Aggregation:** We successfully segmented the dataset into the required age bins using `pd.cut`. The `groupby().agg()` method was then used to efficiently compute the count, mean income, and median score for each group, presenting the results in a clean, tidy DataFrame.\n",
    "\n",
    "* **4. NumPy Operations:** A comprehensive demonstration of fundamental NumPy operations was provided. This included array shape manipulation, negative indexing, showcasing a slicing error, and performing arithmetic operations like broadcasting and the dot product. Key linear algebra functions like calculating a determinant and matrix inverse were also successfully executed.\n",
    "\n",
    "### Key Learnings:\n",
    "\n",
    "This assignment provided practical experience in several core data science concepts:\n",
    "* The critical importance of setting a `random.seed` for creating reproducible analyses.\n",
    "* How different measures of central tendency (mean, median, weighted mean) can provide different insights into a dataset.\n",
    "* The utility of z-scores as a universal method for identifying statistical outliers.\n",
    "* The power and efficiency of using `groupby().agg()` to perform complex data summaries in a single command.\n",
    "\n",
    "All assignment requirements have been met, and the solutions have been presented in a clean, well-documented, and reproducible format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
